{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [**Introduction à l'ingénierie manuelle de caractéristiques (partie 2)**](https://www.kaggle.com/code/willkoehrsen/introduction-to-manual-feature-engineering-p2/notebook)\n",
    "\n",
    "180 votes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous allons développer le travail effectué dans le notebook [**Introduction à l'ingénierie de features manuelle (partie 1)**](https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering/output). Nous utiliserons les fonctions d'agrégation et de comptage de valeurs développées dans ce notebook pour incorporer des informations à partir des fichiers de données `previous_application`, `POS_CASH_balance`, `installments_payments` et `credit_card_balance`. Nous avons déjà utilisé les informations des fichiers `bureau` et `bureau_balance` dans le notebook précédent, ce qui nous a permis d'améliorer notre score de compétition par rapport à l'utilisation uniquement des données de l'application. Après avoir exécuté un modèle avec les features incluses ici, les performances augmentent, mais nous rencontrons des problèmes liés à une explosion du nombre de features ! Je travaille sur un notebook de sélection de features, mais pour ce notebook, nous allons continuer à construire un ensemble de données riche pour notre modèle.\n",
    "\n",
    "Les définitions des quatre fichiers de données supplémentaires sont les suivantes :\n",
    "\n",
    "* `previous_application` (appelé `previous`) : anciennes demandes de prêt chez Home Credit des clients qui ont des prêts dans les données de l'application. Chaque prêt actuel dans les données de l'application peut avoir plusieurs prêts précédents. Chaque demande précédente a une ligne et est identifiée par la feature `SK_ID_PREV`.\n",
    "* `POS_CASH_BALANCE` (appelé `cash`) : données mensuelles sur les prêts précédents en points de vente ou en espèces que les clients ont eus avec Home Credit. Chaque ligne représente un mois d'un prêt précédent en point de vente ou en espèces, et un seul prêt précédent peut avoir plusieurs lignes.\n",
    "* `credit_card_balance` (appelé `credit`) : données mensuelles sur les anciennes cartes de crédit que les clients ont eues chez Home Credit. Chaque ligne représente un mois de solde d'une carte de crédit, et une seule carte de crédit peut avoir plusieurs lignes.\n",
    "* `installments_payment` (appelé `installments`) : historique des paiements des anciens prêts chez Home Credit. Il y a une ligne pour chaque paiement effectué et une ligne pour chaque paiement manqué."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions\n",
    "\n",
    "Nous avons passé un certain temps à développer deux fonctions dans le notebook précédent :\n",
    "\n",
    "* `agg_numeric` : calcul des statistiques d'agrégation (`moyenne`, `compte`, `max`, `min`) pour les variables numériques.\n",
    "* `agg_categorical` : calcul des comptages et des comptages normalisés de chaque catégorie dans une variable catégorielle.\n",
    "\n",
    "Ensemble, ces deux fonctions peuvent extraire des informations à la fois sur les données numériques et catégorielles d'un dataframe. Notre approche générale consistera à appliquer ces deux fonctions aux dataframes, en regroupant par l'identifiant du client, `SK_ID_CURR`. Pour les fichiers `POS_CASH_balance`, `credit_card_balance` et `installment_payments`, nous pouvons d'abord regrouper par l'identifiant unique du prêt précédent, `SK_ID_PREV`. Ensuite, nous regrouperons le dataframe résultant par `SK_ID_CURR` pour calculer les statistiques d'agrégation pour chaque client sur l'ensemble de ses prêts précédents. Si cela vous semble un peu confus, je vous suggère de retourner au **[premier notebook d'ingénierie de features](https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering/output).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings from pandas\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Memory management\n",
    "import gc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction pour agréger des données numériques\n",
    "\n",
    "Cette fonction regroupe les données selon la variable `group_var` et calcule la moyenne (`mean`), le maximum (`max`), le minimum (`min`) et la somme (`sum`). Par défaut, elle ne s'applique qu'aux données numériques dans pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_numeric(df, parent_var, df_name):\n",
    "    \"\"\"\n",
    "    Groups and aggregates the numeric values in a child dataframe\n",
    "    by the parent variable.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        df (dataframe): \n",
    "            the child dataframe to calculate the statistics on\n",
    "        parent_var (string): \n",
    "            the parent variable used for grouping and aggregating\n",
    "        df_name (string): \n",
    "            the variable used to rename the columns\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        agg (dataframe): \n",
    "            a dataframe with the statistics aggregated by the `parent_var` for \n",
    "            all numeric columns. Each observation of the parent variable will have \n",
    "            one row in the dataframe with the parent variable as the index. \n",
    "            The columns are also renamed using the `df_name`. Columns with all duplicate\n",
    "            values are removed. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove id variables other than grouping variable\n",
    "    for col in df:\n",
    "        if col != parent_var and 'SK_ID' in col:\n",
    "            df = df.drop(columns = col)\n",
    "\n",
    "    # Only want the numeric variables\n",
    "    parent_ids = df[parent_var].copy()\n",
    "    numeric_df = df.select_dtypes('number').copy()\n",
    "    numeric_df[parent_var] = parent_ids\n",
    "\n",
    "    # Group by the specified variable and calculate the statistics\n",
    "    agg = numeric_df.groupby(parent_var).agg(['count', 'mean', 'max', 'min', 'sum'])\n",
    "\n",
    "    # Need to create new column names\n",
    "    columns = []\n",
    "\n",
    "    # Iterate through the variables names\n",
    "    for var in agg.columns.levels[0]:\n",
    "        if var != parent_var:\n",
    "            # Iterate through the stat names\n",
    "            columns.extend(\n",
    "                f'{df_name}_{var}_{stat}'\n",
    "                for stat in agg.columns.levels[1]\n",
    "            )\n",
    "    agg.columns = columns\n",
    "\n",
    "    # Remove the columns with all redundant values\n",
    "    _, idx = np.unique(agg, axis = 1, return_index=True)\n",
    "    agg = agg.iloc[:, idx]\n",
    "\n",
    "    return agg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction pour calculer les décomptes catégoriels\n",
    "\n",
    "Cette fonction calcule les occurrences (décomptes) de chaque catégorie dans une variable catégorielle pour chaque client. Elle calcule également le décompte normalisé, qui est le décompte d'une catégorie divisé par le décompte total de toutes les catégories dans une variable catégorielle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_categorical(df, parent_var, df_name):\n",
    "    \"\"\"\n",
    "    Aggregates the categorical features in a child dataframe\n",
    "    for each observation of the parent variable.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    df : dataframe \n",
    "        The dataframe to calculate the value counts for.\n",
    "        \n",
    "    parent_var : string\n",
    "        The variable by which to group and aggregate the dataframe. For each unique\n",
    "        value of this variable, the final dataframe will have one row\n",
    "        \n",
    "    df_name : string\n",
    "        Variable added to the front of column names to keep track of columns\n",
    "\n",
    "    \n",
    "    Return\n",
    "    --------\n",
    "    categorical : dataframe\n",
    "        A dataframe with aggregated statistics for each observation of the parent_var\n",
    "        The columns are also renamed and columns with duplicate values are removed.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Select the categorical columns\n",
    "    categorical = pd.get_dummies(df.select_dtypes('category'))\n",
    "\n",
    "    # Make sure to put the identifying id on the column\n",
    "    categorical[parent_var] = df[parent_var]\n",
    "\n",
    "    # Groupby the group var and calculate the sum and mean\n",
    "    categorical = categorical.groupby(parent_var).agg(['sum', 'count', 'mean'])\n",
    "\n",
    "    column_names = []\n",
    "\n",
    "    # Iterate through the columns in level 0\n",
    "    for var in categorical.columns.levels[0]:\n",
    "        # Iterate through the stats in level 1\n",
    "        column_names.extend(\n",
    "            f'{df_name}_{var}_{stat}'\n",
    "            for stat in ['sum', 'count', 'mean']\n",
    "        )\n",
    "    categorical.columns = column_names\n",
    "\n",
    "    # Remove duplicate columns by values\n",
    "    _, idx = np.unique(categorical, axis = 1, return_index = True)\n",
    "    categorical = categorical.iloc[:, idx]\n",
    "\n",
    "    return categorical"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction pour les tracés de distribution des variables\n",
    "\n",
    "Nous avons également créé une fonction qui trace la distribution de la variable en fonction de la valeur de `TARGET` (soit 1 pour les clients n'ayant pas remboursé le prêt, soit 0 pour les clients ayant remboursé le prêt). Nous pouvons utiliser cette fonction pour examiner visuellement les nouvelles variables que nous créons. Elle calcule également le coefficient de corrélation de la variable avec la cible, ce qui peut être utilisé comme une approximation de la pertinence de la variable créée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the disribution of a variable colored by value of the target\n",
    "def kde_target(var_name, df):\n",
    "    \n",
    "    # Calculate the correlation coefficient between the new variable and the target\n",
    "    corr = df['TARGET'].corr(df[var_name])\n",
    "\n",
    "    # Calculate medians for repaid vs not repaid\n",
    "    avg_repaid = df.ix[df['TARGET'] == 0, var_name].median()\n",
    "    avg_not_repaid = df.ix[df['TARGET'] == 1, var_name].median()\n",
    "\n",
    "    plt.figure(figsize = (12, 6))\n",
    "\n",
    "    # Plot the distribution for target == 0 and target == 1\n",
    "    sns.kdeplot(df.ix[df['TARGET'] == 0, var_name], label = 'TARGET == 0')\n",
    "    sns.kdeplot(df.ix[df['TARGET'] == 1, var_name], label = 'TARGET == 1')\n",
    "\n",
    "    # label the plot\n",
    "    plt.xlabel(var_name)\n",
    "    plt.ylabel('Density')\n",
    "    plt.title(f'{var_name} Distribution')\n",
    "    plt.legend()\n",
    "\n",
    "    # print out the correlation\n",
    "    print('The correlation between %s and the TARGET is %0.4f' % (var_name, corr))\n",
    "    # Print out average values\n",
    "    print('Median value for loan that was not repaid = %0.4f' % avg_not_repaid)\n",
    "    print('Median value for loan that was repaid =     %0.4f' % avg_repaid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction pour convertir les types de données\n",
    "\n",
    "Cela permet de réduire l'utilisation de la mémoire en utilisant des types plus efficaces pour les variables. Par exemple, le type `category` est souvent préférable au type `object` (sauf si le nombre de catégories uniques est proche du nombre de lignes dans le dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def return_size(df):\n",
    "    \"\"\"Return size of dataframe in gigabytes\"\"\"\n",
    "    return round(sys.getsizeof(df) / 1e9, 2)\n",
    "\n",
    "def convert_types(df, print_info = False):\n",
    "    \n",
    "    original_memory = df.memory_usage().sum()\n",
    "    \n",
    "    # Iterate through each column\n",
    "    for c in df:\n",
    "        \n",
    "        # Convert ids and booleans to integers\n",
    "        if ('SK_ID' in c):\n",
    "            df[c] = df[c].fillna(0).astype(np.int32)\n",
    "            \n",
    "        # Convert objects to category\n",
    "        elif (df[c].dtype == 'object') and (df[c].nunique() < df.shape[0]):\n",
    "            df[c] = df[c].astype('category')\n",
    "        \n",
    "        # Booleans mapped to integers\n",
    "        elif list(df[c].unique()) == [1, 0]:\n",
    "            df[c] = df[c].astype(bool)\n",
    "        \n",
    "        # Float64 to float32\n",
    "        elif df[c].dtype == float:\n",
    "            df[c] = df[c].astype(np.float32)\n",
    "            \n",
    "        # Int64 to int32\n",
    "        elif df[c].dtype == int:\n",
    "            df[c] = df[c].astype(np.int32)\n",
    "        \n",
    "    new_memory = df.memory_usage().sum()\n",
    "    \n",
    "    if print_info:\n",
    "        print(f'Original Memory Usage: {round(original_memory / 1e9, 2)} gb.')\n",
    "        print(f'New Memory Usage: {round(new_memory / 1e9, 2)} gb.')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traitons un dataframe à la fois. Commençons par `previous_applications`. Celui-ci contient une ligne pour chaque prêt précédent qu'un client avait chez Home Credit. Un client peut avoir plusieurs prêts précédents, c'est pourquoi nous devons agréger des statistiques pour chaque client."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `previous_application`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Memory Usage: 0.49 gb.\n",
      "New Memory Usage: 0.18 gb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_APPLICATION</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_DOWN_PAYMENT</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START</th>\n",
       "      <th>HOUR_APPR_PROCESS_START</th>\n",
       "      <th>...</th>\n",
       "      <th>NAME_SELLER_INDUSTRY</th>\n",
       "      <th>CNT_PAYMENT</th>\n",
       "      <th>NAME_YIELD_GROUP</th>\n",
       "      <th>PRODUCT_COMBINATION</th>\n",
       "      <th>DAYS_FIRST_DRAWING</th>\n",
       "      <th>DAYS_FIRST_DUE</th>\n",
       "      <th>DAYS_LAST_DUE_1ST_VERSION</th>\n",
       "      <th>DAYS_LAST_DUE</th>\n",
       "      <th>DAYS_TERMINATION</th>\n",
       "      <th>NFLAG_INSURED_ON_APPROVAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2030495</td>\n",
       "      <td>271877</td>\n",
       "      <td>Consumer loans</td>\n",
       "      <td>1730.430054</td>\n",
       "      <td>17145.0</td>\n",
       "      <td>17145.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17145.0</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>Connectivity</td>\n",
       "      <td>12.0</td>\n",
       "      <td>middle</td>\n",
       "      <td>POS mobile with interest</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2802425</td>\n",
       "      <td>108129</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>25188.615234</td>\n",
       "      <td>607500.0</td>\n",
       "      <td>679671.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>607500.0</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>36.0</td>\n",
       "      <td>low_action</td>\n",
       "      <td>Cash X-Sell: low</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2523466</td>\n",
       "      <td>122040</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>15060.735352</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>136444.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>TUESDAY</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>12.0</td>\n",
       "      <td>high</td>\n",
       "      <td>Cash X-Sell: high</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-271.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2819243</td>\n",
       "      <td>176158</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>47041.335938</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>470790.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>12.0</td>\n",
       "      <td>middle</td>\n",
       "      <td>Cash X-Sell: middle</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-482.0</td>\n",
       "      <td>-152.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1784265</td>\n",
       "      <td>202054</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>31924.394531</td>\n",
       "      <td>337500.0</td>\n",
       "      <td>404055.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>337500.0</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>24.0</td>\n",
       "      <td>high</td>\n",
       "      <td>Cash Street: high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_PREV  SK_ID_CURR NAME_CONTRACT_TYPE   AMT_ANNUITY  AMT_APPLICATION  \\\n",
       "0     2030495      271877     Consumer loans   1730.430054          17145.0   \n",
       "1     2802425      108129         Cash loans  25188.615234         607500.0   \n",
       "2     2523466      122040         Cash loans  15060.735352         112500.0   \n",
       "3     2819243      176158         Cash loans  47041.335938         450000.0   \n",
       "4     1784265      202054         Cash loans  31924.394531         337500.0   \n",
       "\n",
       "   AMT_CREDIT  AMT_DOWN_PAYMENT  AMT_GOODS_PRICE WEEKDAY_APPR_PROCESS_START  \\\n",
       "0     17145.0               0.0          17145.0                   SATURDAY   \n",
       "1    679671.0               NaN         607500.0                   THURSDAY   \n",
       "2    136444.5               NaN         112500.0                    TUESDAY   \n",
       "3    470790.0               NaN         450000.0                     MONDAY   \n",
       "4    404055.0               NaN         337500.0                   THURSDAY   \n",
       "\n",
       "   HOUR_APPR_PROCESS_START  ... NAME_SELLER_INDUSTRY  CNT_PAYMENT  \\\n",
       "0                       15  ...         Connectivity         12.0   \n",
       "1                       11  ...                  XNA         36.0   \n",
       "2                       11  ...                  XNA         12.0   \n",
       "3                        7  ...                  XNA         12.0   \n",
       "4                        9  ...                  XNA         24.0   \n",
       "\n",
       "   NAME_YIELD_GROUP       PRODUCT_COMBINATION  DAYS_FIRST_DRAWING  \\\n",
       "0            middle  POS mobile with interest            365243.0   \n",
       "1        low_action          Cash X-Sell: low            365243.0   \n",
       "2              high         Cash X-Sell: high            365243.0   \n",
       "3            middle       Cash X-Sell: middle            365243.0   \n",
       "4              high         Cash Street: high                 NaN   \n",
       "\n",
       "  DAYS_FIRST_DUE DAYS_LAST_DUE_1ST_VERSION  DAYS_LAST_DUE DAYS_TERMINATION  \\\n",
       "0          -42.0                     300.0          -42.0            -37.0   \n",
       "1         -134.0                     916.0       365243.0         365243.0   \n",
       "2         -271.0                      59.0       365243.0         365243.0   \n",
       "3         -482.0                    -152.0         -182.0           -177.0   \n",
       "4            NaN                       NaN            NaN              NaN   \n",
       "\n",
       "  NFLAG_INSURED_ON_APPROVAL  \n",
       "0                       0.0  \n",
       "1                       1.0  \n",
       "2                       1.0  \n",
       "3                       1.0  \n",
       "4                       NaN  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous = pd.read_csv('../../../pepper_credit_scoring_tool/dataset/csv/previous_application.csv')\n",
    "previous = convert_types(previous, print_info=True)\n",
    "previous.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous aggregation shape:  (338857, 80)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_DAYS_DECISION_sum</th>\n",
       "      <th>previous_DAYS_DECISION_min</th>\n",
       "      <th>previous_DAYS_DECISION_mean</th>\n",
       "      <th>previous_DAYS_DECISION_max</th>\n",
       "      <th>previous_DAYS_FIRST_DUE_sum</th>\n",
       "      <th>previous_DAYS_FIRST_DUE_min</th>\n",
       "      <th>previous_DAYS_FIRST_DUE_mean</th>\n",
       "      <th>previous_DAYS_FIRST_DUE_max</th>\n",
       "      <th>previous_DAYS_LAST_DUE_sum</th>\n",
       "      <th>previous_DAYS_LAST_DUE_min</th>\n",
       "      <th>...</th>\n",
       "      <th>previous_DAYS_FIRST_DRAWING_min</th>\n",
       "      <th>previous_DAYS_FIRST_DRAWING_mean</th>\n",
       "      <th>previous_DAYS_FIRST_DRAWING_max</th>\n",
       "      <th>previous_DAYS_FIRST_DRAWING_sum</th>\n",
       "      <th>previous_RATE_INTEREST_PRIMARY_min</th>\n",
       "      <th>previous_RATE_INTEREST_PRIMARY_mean</th>\n",
       "      <th>previous_RATE_INTEREST_PRIMARY_max</th>\n",
       "      <th>previous_RATE_INTEREST_PRIVILEGED_min</th>\n",
       "      <th>previous_RATE_INTEREST_PRIVILEGED_mean</th>\n",
       "      <th>previous_RATE_INTEREST_PRIVILEGED_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>-1740</td>\n",
       "      <td>-1740</td>\n",
       "      <td>-1740.0</td>\n",
       "      <td>-1740</td>\n",
       "      <td>-1709.0</td>\n",
       "      <td>-1709.0</td>\n",
       "      <td>-1709.000000</td>\n",
       "      <td>-1709.0</td>\n",
       "      <td>-1619.0</td>\n",
       "      <td>-1619.0</td>\n",
       "      <td>...</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>-606</td>\n",
       "      <td>-606</td>\n",
       "      <td>-606.0</td>\n",
       "      <td>-606</td>\n",
       "      <td>-565.0</td>\n",
       "      <td>-565.0</td>\n",
       "      <td>-565.000000</td>\n",
       "      <td>-565.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>-3915</td>\n",
       "      <td>-2341</td>\n",
       "      <td>-1305.0</td>\n",
       "      <td>-746</td>\n",
       "      <td>-3823.0</td>\n",
       "      <td>-2310.0</td>\n",
       "      <td>-1274.333374</td>\n",
       "      <td>-716.0</td>\n",
       "      <td>-3163.0</td>\n",
       "      <td>-1980.0</td>\n",
       "      <td>...</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>1095729.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>-815</td>\n",
       "      <td>-815</td>\n",
       "      <td>-815.0</td>\n",
       "      <td>-815</td>\n",
       "      <td>-784.0</td>\n",
       "      <td>-784.0</td>\n",
       "      <td>-784.000000</td>\n",
       "      <td>-784.0</td>\n",
       "      <td>-724.0</td>\n",
       "      <td>-724.0</td>\n",
       "      <td>...</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100005</th>\n",
       "      <td>-1072</td>\n",
       "      <td>-757</td>\n",
       "      <td>-536.0</td>\n",
       "      <td>-315</td>\n",
       "      <td>-706.0</td>\n",
       "      <td>-706.0</td>\n",
       "      <td>-706.000000</td>\n",
       "      <td>-706.0</td>\n",
       "      <td>-466.0</td>\n",
       "      <td>-466.0</td>\n",
       "      <td>...</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            previous_DAYS_DECISION_sum  previous_DAYS_DECISION_min  \\\n",
       "SK_ID_CURR                                                           \n",
       "100001                           -1740                       -1740   \n",
       "100002                            -606                        -606   \n",
       "100003                           -3915                       -2341   \n",
       "100004                            -815                        -815   \n",
       "100005                           -1072                        -757   \n",
       "\n",
       "            previous_DAYS_DECISION_mean  previous_DAYS_DECISION_max  \\\n",
       "SK_ID_CURR                                                            \n",
       "100001                          -1740.0                       -1740   \n",
       "100002                           -606.0                        -606   \n",
       "100003                          -1305.0                        -746   \n",
       "100004                           -815.0                        -815   \n",
       "100005                           -536.0                        -315   \n",
       "\n",
       "            previous_DAYS_FIRST_DUE_sum  previous_DAYS_FIRST_DUE_min  \\\n",
       "SK_ID_CURR                                                             \n",
       "100001                          -1709.0                      -1709.0   \n",
       "100002                           -565.0                       -565.0   \n",
       "100003                          -3823.0                      -2310.0   \n",
       "100004                           -784.0                       -784.0   \n",
       "100005                           -706.0                       -706.0   \n",
       "\n",
       "            previous_DAYS_FIRST_DUE_mean  previous_DAYS_FIRST_DUE_max  \\\n",
       "SK_ID_CURR                                                              \n",
       "100001                      -1709.000000                      -1709.0   \n",
       "100002                       -565.000000                       -565.0   \n",
       "100003                      -1274.333374                       -716.0   \n",
       "100004                       -784.000000                       -784.0   \n",
       "100005                       -706.000000                       -706.0   \n",
       "\n",
       "            previous_DAYS_LAST_DUE_sum  previous_DAYS_LAST_DUE_min  ...  \\\n",
       "SK_ID_CURR                                                          ...   \n",
       "100001                         -1619.0                     -1619.0  ...   \n",
       "100002                           -25.0                       -25.0  ...   \n",
       "100003                         -3163.0                     -1980.0  ...   \n",
       "100004                          -724.0                      -724.0  ...   \n",
       "100005                          -466.0                      -466.0  ...   \n",
       "\n",
       "            previous_DAYS_FIRST_DRAWING_min  previous_DAYS_FIRST_DRAWING_mean  \\\n",
       "SK_ID_CURR                                                                      \n",
       "100001                             365243.0                          365243.0   \n",
       "100002                             365243.0                          365243.0   \n",
       "100003                             365243.0                          365243.0   \n",
       "100004                             365243.0                          365243.0   \n",
       "100005                             365243.0                          365243.0   \n",
       "\n",
       "            previous_DAYS_FIRST_DRAWING_max  previous_DAYS_FIRST_DRAWING_sum  \\\n",
       "SK_ID_CURR                                                                     \n",
       "100001                             365243.0                         365243.0   \n",
       "100002                             365243.0                         365243.0   \n",
       "100003                             365243.0                        1095729.0   \n",
       "100004                             365243.0                         365243.0   \n",
       "100005                             365243.0                         365243.0   \n",
       "\n",
       "            previous_RATE_INTEREST_PRIMARY_min  \\\n",
       "SK_ID_CURR                                       \n",
       "100001                                     NaN   \n",
       "100002                                     NaN   \n",
       "100003                                     NaN   \n",
       "100004                                     NaN   \n",
       "100005                                     NaN   \n",
       "\n",
       "            previous_RATE_INTEREST_PRIMARY_mean  \\\n",
       "SK_ID_CURR                                        \n",
       "100001                                      NaN   \n",
       "100002                                      NaN   \n",
       "100003                                      NaN   \n",
       "100004                                      NaN   \n",
       "100005                                      NaN   \n",
       "\n",
       "            previous_RATE_INTEREST_PRIMARY_max  \\\n",
       "SK_ID_CURR                                       \n",
       "100001                                     NaN   \n",
       "100002                                     NaN   \n",
       "100003                                     NaN   \n",
       "100004                                     NaN   \n",
       "100005                                     NaN   \n",
       "\n",
       "            previous_RATE_INTEREST_PRIVILEGED_min  \\\n",
       "SK_ID_CURR                                          \n",
       "100001                                        NaN   \n",
       "100002                                        NaN   \n",
       "100003                                        NaN   \n",
       "100004                                        NaN   \n",
       "100005                                        NaN   \n",
       "\n",
       "            previous_RATE_INTEREST_PRIVILEGED_mean  \\\n",
       "SK_ID_CURR                                           \n",
       "100001                                         NaN   \n",
       "100002                                         NaN   \n",
       "100003                                         NaN   \n",
       "100004                                         NaN   \n",
       "100005                                         NaN   \n",
       "\n",
       "            previous_RATE_INTEREST_PRIVILEGED_max  \n",
       "SK_ID_CURR                                         \n",
       "100001                                        NaN  \n",
       "100002                                        NaN  \n",
       "100003                                        NaN  \n",
       "100004                                        NaN  \n",
       "100005                                        NaN  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate aggregate statistics for each numeric column\n",
    "previous_agg = agg_numeric(previous, 'SK_ID_CURR', 'previous')\n",
    "print('Previous aggregation shape: ', previous_agg.shape)\n",
    "previous_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous counts shape:  (338857, 285)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_NAME_GOODS_CATEGORY_Animals_mean</th>\n",
       "      <th>previous_NAME_GOODS_CATEGORY_Animals_sum</th>\n",
       "      <th>previous_NAME_GOODS_CATEGORY_House Construction_mean</th>\n",
       "      <th>previous_NAME_GOODS_CATEGORY_House Construction_sum</th>\n",
       "      <th>previous_NAME_CASH_LOAN_PURPOSE_Refusal to name the goal_mean</th>\n",
       "      <th>previous_NAME_CASH_LOAN_PURPOSE_Refusal to name the goal_sum</th>\n",
       "      <th>previous_NAME_CASH_LOAN_PURPOSE_Money for a third person_mean</th>\n",
       "      <th>previous_NAME_CASH_LOAN_PURPOSE_Money for a third person_sum</th>\n",
       "      <th>previous_NAME_CASH_LOAN_PURPOSE_Hobby_mean</th>\n",
       "      <th>previous_NAME_CASH_LOAN_PURPOSE_Hobby_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>previous_CODE_REJECT_REASON_XAP_mean</th>\n",
       "      <th>previous_FLAG_LAST_APPL_PER_CONTRACT_Y_mean</th>\n",
       "      <th>previous_NAME_PORTFOLIO_POS_sum</th>\n",
       "      <th>previous_NAME_CONTRACT_TYPE_Consumer loans_sum</th>\n",
       "      <th>previous_NAME_CASH_LOAN_PURPOSE_XAP_sum</th>\n",
       "      <th>previous_NAME_PRODUCT_TYPE_XNA_sum</th>\n",
       "      <th>previous_NAME_CONTRACT_STATUS_Approved_sum</th>\n",
       "      <th>previous_CODE_REJECT_REASON_XAP_sum</th>\n",
       "      <th>previous_FLAG_LAST_APPL_PER_CONTRACT_Y_sum</th>\n",
       "      <th>previous_NAME_CONTRACT_TYPE_Cash loans_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100005</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            previous_NAME_GOODS_CATEGORY_Animals_mean  \\\n",
       "SK_ID_CURR                                              \n",
       "100001                                            0.0   \n",
       "100002                                            0.0   \n",
       "100003                                            0.0   \n",
       "100004                                            0.0   \n",
       "100005                                            0.0   \n",
       "\n",
       "            previous_NAME_GOODS_CATEGORY_Animals_sum  \\\n",
       "SK_ID_CURR                                             \n",
       "100001                                             0   \n",
       "100002                                             0   \n",
       "100003                                             0   \n",
       "100004                                             0   \n",
       "100005                                             0   \n",
       "\n",
       "            previous_NAME_GOODS_CATEGORY_House Construction_mean  \\\n",
       "SK_ID_CURR                                                         \n",
       "100001                                                    0.0      \n",
       "100002                                                    0.0      \n",
       "100003                                                    0.0      \n",
       "100004                                                    0.0      \n",
       "100005                                                    0.0      \n",
       "\n",
       "            previous_NAME_GOODS_CATEGORY_House Construction_sum  \\\n",
       "SK_ID_CURR                                                        \n",
       "100001                                                      0     \n",
       "100002                                                      0     \n",
       "100003                                                      0     \n",
       "100004                                                      0     \n",
       "100005                                                      0     \n",
       "\n",
       "            previous_NAME_CASH_LOAN_PURPOSE_Refusal to name the goal_mean  \\\n",
       "SK_ID_CURR                                                                  \n",
       "100001                                                    0.0               \n",
       "100002                                                    0.0               \n",
       "100003                                                    0.0               \n",
       "100004                                                    0.0               \n",
       "100005                                                    0.0               \n",
       "\n",
       "            previous_NAME_CASH_LOAN_PURPOSE_Refusal to name the goal_sum  \\\n",
       "SK_ID_CURR                                                                 \n",
       "100001                                                      0              \n",
       "100002                                                      0              \n",
       "100003                                                      0              \n",
       "100004                                                      0              \n",
       "100005                                                      0              \n",
       "\n",
       "            previous_NAME_CASH_LOAN_PURPOSE_Money for a third person_mean  \\\n",
       "SK_ID_CURR                                                                  \n",
       "100001                                                    0.0               \n",
       "100002                                                    0.0               \n",
       "100003                                                    0.0               \n",
       "100004                                                    0.0               \n",
       "100005                                                    0.0               \n",
       "\n",
       "            previous_NAME_CASH_LOAN_PURPOSE_Money for a third person_sum  \\\n",
       "SK_ID_CURR                                                                 \n",
       "100001                                                      0              \n",
       "100002                                                      0              \n",
       "100003                                                      0              \n",
       "100004                                                      0              \n",
       "100005                                                      0              \n",
       "\n",
       "            previous_NAME_CASH_LOAN_PURPOSE_Hobby_mean  \\\n",
       "SK_ID_CURR                                               \n",
       "100001                                             0.0   \n",
       "100002                                             0.0   \n",
       "100003                                             0.0   \n",
       "100004                                             0.0   \n",
       "100005                                             0.0   \n",
       "\n",
       "            previous_NAME_CASH_LOAN_PURPOSE_Hobby_sum  ...  \\\n",
       "SK_ID_CURR                                             ...   \n",
       "100001                                              0  ...   \n",
       "100002                                              0  ...   \n",
       "100003                                              0  ...   \n",
       "100004                                              0  ...   \n",
       "100005                                              0  ...   \n",
       "\n",
       "            previous_CODE_REJECT_REASON_XAP_mean  \\\n",
       "SK_ID_CURR                                         \n",
       "100001                                       1.0   \n",
       "100002                                       1.0   \n",
       "100003                                       1.0   \n",
       "100004                                       1.0   \n",
       "100005                                       1.0   \n",
       "\n",
       "            previous_FLAG_LAST_APPL_PER_CONTRACT_Y_mean  \\\n",
       "SK_ID_CURR                                                \n",
       "100001                                              1.0   \n",
       "100002                                              1.0   \n",
       "100003                                              1.0   \n",
       "100004                                              1.0   \n",
       "100005                                              1.0   \n",
       "\n",
       "            previous_NAME_PORTFOLIO_POS_sum  \\\n",
       "SK_ID_CURR                                    \n",
       "100001                                    1   \n",
       "100002                                    1   \n",
       "100003                                    2   \n",
       "100004                                    1   \n",
       "100005                                    1   \n",
       "\n",
       "            previous_NAME_CONTRACT_TYPE_Consumer loans_sum  \\\n",
       "SK_ID_CURR                                                   \n",
       "100001                                                   1   \n",
       "100002                                                   1   \n",
       "100003                                                   2   \n",
       "100004                                                   1   \n",
       "100005                                                   1   \n",
       "\n",
       "            previous_NAME_CASH_LOAN_PURPOSE_XAP_sum  \\\n",
       "SK_ID_CURR                                            \n",
       "100001                                            1   \n",
       "100002                                            1   \n",
       "100003                                            2   \n",
       "100004                                            1   \n",
       "100005                                            1   \n",
       "\n",
       "            previous_NAME_PRODUCT_TYPE_XNA_sum  \\\n",
       "SK_ID_CURR                                       \n",
       "100001                                       1   \n",
       "100002                                       1   \n",
       "100003                                       2   \n",
       "100004                                       1   \n",
       "100005                                       2   \n",
       "\n",
       "            previous_NAME_CONTRACT_STATUS_Approved_sum  \\\n",
       "SK_ID_CURR                                               \n",
       "100001                                               1   \n",
       "100002                                               1   \n",
       "100003                                               3   \n",
       "100004                                               1   \n",
       "100005                                               1   \n",
       "\n",
       "            previous_CODE_REJECT_REASON_XAP_sum  \\\n",
       "SK_ID_CURR                                        \n",
       "100001                                        1   \n",
       "100002                                        1   \n",
       "100003                                        3   \n",
       "100004                                        1   \n",
       "100005                                        2   \n",
       "\n",
       "            previous_FLAG_LAST_APPL_PER_CONTRACT_Y_sum  \\\n",
       "SK_ID_CURR                                               \n",
       "100001                                               1   \n",
       "100002                                               1   \n",
       "100003                                               3   \n",
       "100004                                               1   \n",
       "100005                                               2   \n",
       "\n",
       "            previous_NAME_CONTRACT_TYPE_Cash loans_count  \n",
       "SK_ID_CURR                                                \n",
       "100001                                                 1  \n",
       "100002                                                 1  \n",
       "100003                                                 3  \n",
       "100004                                                 1  \n",
       "100005                                                 2  \n",
       "\n",
       "[5 rows x 285 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate value counts for each categorical column\n",
    "previous_counts = agg_categorical(previous, 'SK_ID_CURR', 'previous')\n",
    "print('Previous counts shape: ', previous_counts.shape)\n",
    "previous_counts.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons joindre le dataframe calculé au dataframe d'entraînement principal en utilisant une fusion (`merge`). Ensuite, nous devrions supprimer les dataframes calculés pour éviter d'utiliser trop de mémoire du noyau (`kernel`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../../../pepper_credit_scoring_tool/dataset/csv/application_train.csv')\n",
    "train = convert_types(train)\n",
    "test = pd.read_csv('../../../pepper_credit_scoring_tool/dataset/csv/application_test.csv')\n",
    "test = convert_types(test)\n",
    "\n",
    "# Merge in the previous information\n",
    "train = train.merge(previous_counts, on='SK_ID_CURR', how='left')\n",
    "train = train.merge(previous_agg, on='SK_ID_CURR', how='left')\n",
    "\n",
    "test = test.merge(previous_counts, on='SK_ID_CURR', how='left')\n",
    "test = test.merge(previous_agg, on='SK_ID_CURR', how='left')\n",
    "\n",
    "# Remove variables to free memory\n",
    "gc.enable()\n",
    "del previous, previous_agg, previous_counts\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous devons faire attention à ne pas calculer trop de variables. Nous ne voulons pas surcharger le modèle avec trop de variables non pertinentes ou avec trop de valeurs manquantes. Dans le notebook précédent, nous avons supprimé toutes les variables ayant plus de 75% de valeurs manquantes. Pour être cohérent, nous appliquerons la même logique ici."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction pour calculer les valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate missing values by column# Funct \n",
    "def missing_values_table(df, print_info = False):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "\n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "\n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "\n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "\n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "\n",
    "        if print_info:\n",
    "            # Print some summary information\n",
    "            print(\n",
    "                ((f\"Your selected dataframe has {str(df.shape[1])}\" +\n",
    "                    \" columns.\\n\"\n",
    "                    \"There are \") + str(mis_val_table_ren_columns.shape[0]) +\n",
    "                    \" columns that have missing values.\"))\n",
    "\n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_columns(train, test, threshold = 90):\n",
    "    # Calculate missing stats for train and test (remember to calculate a percent!)\n",
    "    train_miss = pd.DataFrame(train.isnull().sum())\n",
    "    train_miss['percent'] = 100 * train_miss[0] / len(train)\n",
    "    \n",
    "    test_miss = pd.DataFrame(test.isnull().sum())\n",
    "    test_miss['percent'] = 100 * test_miss[0] / len(test)\n",
    "    \n",
    "    # list of missing columns for train and test\n",
    "    missing_train_columns = list(train_miss.index[train_miss['percent'] > threshold])\n",
    "    missing_test_columns = list(test_miss.index[test_miss['percent'] > threshold])\n",
    "    \n",
    "    # Combine the two lists together\n",
    "    missing_columns = list(set(missing_train_columns + missing_test_columns))\n",
    "    \n",
    "    # Print information\n",
    "    print('There are %d columns with greater than %d%% missing values.' % (len(missing_columns), threshold))\n",
    "    \n",
    "    # Drop the missing columns and return\n",
    "    train = train.drop(columns = missing_columns)\n",
    "    test = test.drop(columns = missing_columns)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 columns with greater than 90% missing values.\n"
     ]
    }
   ],
   "source": [
    "train, test = remove_missing_columns(train, test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application à davantage de données\n",
    "\n",
    "### Fonction pour agréger les statistiques au niveau du client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_client(df, group_vars, df_names):\n",
    "    \"\"\"Aggregate a dataframe with data at the loan level \n",
    "    at the client level\n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): data at the loan level\n",
    "        group_vars (list of two strings): grouping variables for the loan \n",
    "        and then the client (example ['SK_ID_PREV', 'SK_ID_CURR'])\n",
    "        names (list of two strings): names to call the resulting columns\n",
    "        (example ['cash', 'client'])\n",
    "        \n",
    "    Returns:\n",
    "        df_client (dataframe): aggregated numeric stats at the client level. \n",
    "        Each client will have a single row with all the numeric data aggregated\n",
    "    \"\"\"\n",
    "    \n",
    "    # Aggregate the numeric columns\n",
    "    df_agg = agg_numeric(df, parent_var = group_vars[0], df_name = df_names[0])\n",
    "    \n",
    "    # If there are categorical variables\n",
    "    if any(df.dtypes == 'category'):\n",
    "    \n",
    "        # Count the categorical columns\n",
    "        df_counts = agg_categorical(df, parent_var = group_vars[0], df_name = df_names[0])\n",
    "\n",
    "        # Merge the numeric and categorical\n",
    "        df_by_loan = df_counts.merge(df_agg, on = group_vars[0], how = 'outer')\n",
    "\n",
    "        gc.enable()\n",
    "        del df_agg, df_counts\n",
    "        gc.collect()\n",
    "\n",
    "        # Merge to get the client id in dataframe\n",
    "        df_by_loan = df_by_loan.merge(df[[group_vars[0], group_vars[1]]], on = group_vars[0], how = 'left')\n",
    "\n",
    "        # Remove the loan id\n",
    "        df_by_loan = df_by_loan.drop(columns = [group_vars[0]])\n",
    "\n",
    "        # Aggregate numeric stats by column\n",
    "        df_by_client = agg_numeric(df_by_loan, parent_var = group_vars[1], df_name = df_names[1])\n",
    "\n",
    "        \n",
    "    # No categorical variables\n",
    "    else:\n",
    "        # Merge to get the client id in dataframe\n",
    "        df_by_loan = df_agg.merge(df[[group_vars[0], group_vars[1]]], on = group_vars[0], how = 'left')\n",
    "        \n",
    "        gc.enable()\n",
    "        del df_agg\n",
    "        gc.collect()\n",
    "        \n",
    "        # Remove the loan id\n",
    "        df_by_loan = df_by_loan.drop(columns = [group_vars[0]])\n",
    "        \n",
    "        # Aggregate numeric stats by column\n",
    "        df_by_client = agg_numeric(df_by_loan, parent_var = group_vars[1], df_name = df_names[1])\n",
    "        \n",
    "    # Memory management\n",
    "    gc.enable()\n",
    "    del df, df_by_loan\n",
    "    gc.collect()\n",
    "\n",
    "    return df_by_client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données mensuelles sur les espèces (cash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Memory Usage: 0.64 gb.\n",
      "New Memory Usage: 0.41 gb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>CNT_INSTALMENT</th>\n",
       "      <th>CNT_INSTALMENT_FUTURE</th>\n",
       "      <th>NAME_CONTRACT_STATUS</th>\n",
       "      <th>SK_DPD</th>\n",
       "      <th>SK_DPD_DEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1803195</td>\n",
       "      <td>182943</td>\n",
       "      <td>-31</td>\n",
       "      <td>48.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1715348</td>\n",
       "      <td>367990</td>\n",
       "      <td>-33</td>\n",
       "      <td>36.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1784872</td>\n",
       "      <td>397406</td>\n",
       "      <td>-32</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1903291</td>\n",
       "      <td>269225</td>\n",
       "      <td>-35</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2341044</td>\n",
       "      <td>334279</td>\n",
       "      <td>-35</td>\n",
       "      <td>36.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_PREV  SK_ID_CURR  MONTHS_BALANCE  CNT_INSTALMENT  \\\n",
       "0     1803195      182943             -31            48.0   \n",
       "1     1715348      367990             -33            36.0   \n",
       "2     1784872      397406             -32            12.0   \n",
       "3     1903291      269225             -35            48.0   \n",
       "4     2341044      334279             -35            36.0   \n",
       "\n",
       "   CNT_INSTALMENT_FUTURE NAME_CONTRACT_STATUS  SK_DPD  SK_DPD_DEF  \n",
       "0                   45.0               Active       0           0  \n",
       "1                   35.0               Active       0           0  \n",
       "2                    9.0               Active       0           0  \n",
       "3                   42.0               Active       0           0  \n",
       "4                   35.0               Active       0           0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cash = pd.read_csv('../../../pepper_credit_scoring_tool/dataset/csv/POS_CASH_balance.csv')\n",
    "cash = convert_types(cash, print_info=True)\n",
    "cash.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 992. MiB for an array with shape (13, 10001358) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cash_by_client \u001b[39m=\u001b[39m aggregate_client(cash, group_vars\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mSK_ID_PREV\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mSK_ID_CURR\u001b[39;49m\u001b[39m'\u001b[39;49m], df_names\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mcash\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mclient\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      2\u001b[0m cash_by_client\u001b[39m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[15], line 40\u001b[0m, in \u001b[0;36maggregate_client\u001b[1;34m(df, group_vars, df_names)\u001b[0m\n\u001b[0;32m     37\u001b[0m     df_by_loan \u001b[39m=\u001b[39m df_by_loan\u001b[39m.\u001b[39mdrop(columns \u001b[39m=\u001b[39m [group_vars[\u001b[39m0\u001b[39m]])\n\u001b[0;32m     39\u001b[0m     \u001b[39m# Aggregate numeric stats by column\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     df_by_client \u001b[39m=\u001b[39m agg_numeric(df_by_loan, parent_var \u001b[39m=\u001b[39;49m group_vars[\u001b[39m1\u001b[39;49m], df_name \u001b[39m=\u001b[39;49m df_names[\u001b[39m1\u001b[39;49m])\n\u001b[0;32m     43\u001b[0m \u001b[39m# No categorical variables\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     \u001b[39m# Merge to get the client id in dataframe\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     df_by_loan \u001b[39m=\u001b[39m df_agg\u001b[39m.\u001b[39mmerge(df[[group_vars[\u001b[39m0\u001b[39m], group_vars[\u001b[39m1\u001b[39m]]], on \u001b[39m=\u001b[39m group_vars[\u001b[39m0\u001b[39m], how \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 33\u001b[0m, in \u001b[0;36magg_numeric\u001b[1;34m(df, parent_var, df_name)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39m# Only want the numeric variables\u001b[39;00m\n\u001b[0;32m     32\u001b[0m parent_ids \u001b[39m=\u001b[39m df[parent_var]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m---> 33\u001b[0m numeric_df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mselect_dtypes(\u001b[39m'\u001b[39;49m\u001b[39mnumber\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     34\u001b[0m numeric_df[parent_var] \u001b[39m=\u001b[39m parent_ids\n\u001b[0;32m     36\u001b[0m \u001b[39m# Group by the specified variable and calculate the statistics\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4753\u001b[0m, in \u001b[0;36mDataFrame.select_dtypes\u001b[1;34m(self, include, exclude)\u001b[0m\n\u001b[0;32m   4749\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   4751\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m-> 4753\u001b[0m mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49m_get_data_subset(predicate)\u001b[39m.\u001b[39;49mcopy(deep\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   4754\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)(mgr)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:670\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    667\u001b[0m         res\u001b[39m.\u001b[39m_blklocs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blklocs\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    669\u001b[0m \u001b[39mif\u001b[39;00m deep:\n\u001b[1;32m--> 670\u001b[0m     res\u001b[39m.\u001b[39;49m_consolidate_inplace()\n\u001b[0;32m    671\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1871\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1869\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_consolidated():\n\u001b[0;32m   1870\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1871\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks \u001b[39m=\u001b[39m _consolidate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks)\n\u001b[0;32m   1872\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1873\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefs \u001b[39m=\u001b[39m _consolidate_with_refs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefs)\n",
      "File \u001b[1;32mc:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2329\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2327\u001b[0m new_blocks: \u001b[39mlist\u001b[39m[Block] \u001b[39m=\u001b[39m []\n\u001b[0;32m   2328\u001b[0m \u001b[39mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[39min\u001b[39;00m grouper:\n\u001b[1;32m-> 2329\u001b[0m     merged_blocks, _ \u001b[39m=\u001b[39m _merge_blocks(\n\u001b[0;32m   2330\u001b[0m         \u001b[39mlist\u001b[39;49m(group_blocks), dtype\u001b[39m=\u001b[39;49mdtype, can_consolidate\u001b[39m=\u001b[39;49m_can_consolidate\n\u001b[0;32m   2331\u001b[0m     )\n\u001b[0;32m   2332\u001b[0m     new_blocks \u001b[39m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2333\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32mc:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2388\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2385\u001b[0m     new_values \u001b[39m=\u001b[39m bvals2[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_concat_same_type(bvals2, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m   2387\u001b[0m argsort \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2388\u001b[0m new_values \u001b[39m=\u001b[39m new_values[argsort]\n\u001b[0;32m   2389\u001b[0m new_mgr_locs \u001b[39m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2391\u001b[0m bp \u001b[39m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 992. MiB for an array with shape (13, 10001358) and data type int64"
     ]
    }
   ],
   "source": [
    "cash_by_client = aggregate_client(cash, group_vars=['SK_ID_PREV', 'SK_ID_CURR'], df_names=['cash', 'client'])\n",
    "cash_by_client.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cash by Client Shape: ', cash_by_client.shape)\n",
    "train = train.merge(cash_by_client, on='SK_ID_CURR', how='left')\n",
    "test = test.merge(cash_by_client, on='SK_ID_CURR', how='left')\n",
    "\n",
    "gc.enable()\n",
    "del cash, cash_by_client\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = remove_missing_columns(train, test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données mensuelles sur le crédit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = pd.read_csv('../../../pepper_credit_scoring_tool/dataset/csv/credit_card_balance.csv')\n",
    "credit = convert_types(credit, print_info=True)\n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_by_client = aggregate_client(credit, group_vars = ['SK_ID_PREV', 'SK_ID_CURR'], df_names = ['credit', 'client'])\n",
    "credit_by_client.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Credit by client shape: ', credit_by_client.shape)\n",
    "\n",
    "train = train.merge(credit_by_client, on = 'SK_ID_CURR', how = 'left')\n",
    "test = test.merge(credit_by_client, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "gc.enable()\n",
    "del credit, credit_by_client\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = remove_missing_columns(train, test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Echéances de paiement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments = pd.read_csv('../input/installments_payments.csv')\n",
    "installments = convert_types(installments, print_info=True)\n",
    "installments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments_by_client = aggregate_client(installments, group_vars=['SK_ID_PREV', 'SK_ID_CURR'], df_names=['installments', 'client'])\n",
    "installments_by_client.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Installments by client shape: ', installments_by_client.shape)\n",
    "\n",
    "train = train.merge(installments_by_client, on='SK_ID_CURR', how='left')\n",
    "test = test.merge(installments_by_client, on='SK_ID_CURR', how='left')\n",
    "\n",
    "gc.enable()\n",
    "del installments, installments_by_client\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = remove_missing_columns(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final Training Shape: ', train.shape)\n",
    "print('Final Testing Shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Final training size: {return_size(train)}')\n",
    "print(f'Final testing size: {return_size(test)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enregistrer toutes les nouvelles variables calculées\n",
    "\n",
    "Malheureusement, enregistrer toutes les variables créées ne fonctionne pas dans un notebook Kaggle. Vous devrez exécuter le code sur votre machine personnelle. J'ai exécuté le code et téléchargé les [ensembles de données complets ici](https://www.kaggle.com/willkoehrsen/home-credit-manual-engineered-features). J'ai l'intention de faire une sélection de variables et de télécharger des versions réduites des ensembles de données. Pour l'instant, ils sont légèrement trop volumineux pour être traités dans les notebooks ou les scripts Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv('train_previous_raw.csv', index = False, chunksize = 500)\n",
    "# test.to_csv('test_previous_raw.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(features, test_features, encoding='ohe', n_folds=5):\n",
    "    \n",
    "    \"\"\"Train and test a light gradient boosting model using\n",
    "    cross validation. \n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        features (pd.DataFrame): \n",
    "            dataframe of training features to use \n",
    "            for training a model. Must include the TARGET column.\n",
    "        test_features (pd.DataFrame): \n",
    "            dataframe of testing features to use\n",
    "            for making predictions with the model. \n",
    "        encoding (str, default = 'ohe'): \n",
    "            method for encoding categorical variables. Either 'ohe' for one-hot encoding or 'le' for integer label encoding\n",
    "            n_folds (int, default = 5): number of folds to use for cross validation\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        submission (pd.DataFrame): \n",
    "            dataframe with `SK_ID_CURR` and `TARGET` probabilities\n",
    "            predicted by the model.\n",
    "        feature_importances (pd.DataFrame): \n",
    "            dataframe with the feature importances from the model.\n",
    "        valid_metrics (pd.DataFrame): \n",
    "            dataframe with training and validation metrics (ROC AUC) for each fold and overall.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the ids\n",
    "    train_ids = features['SK_ID_CURR']\n",
    "    test_ids = test_features['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = features['TARGET']\n",
    "    \n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n",
    "    \n",
    "    \n",
    "    # One Hot Encoding\n",
    "    if encoding == 'ohe':\n",
    "        features = pd.get_dummies(features)\n",
    "        test_features = pd.get_dummies(test_features)\n",
    "        \n",
    "        # Align the dataframes by the columns\n",
    "        features, test_features = features.align(test_features, join = 'inner', axis = 1)\n",
    "        \n",
    "        # No categorical indices to record\n",
    "        cat_indices = 'auto'\n",
    "    \n",
    "    # Integer label encoding\n",
    "    elif encoding == 'le':\n",
    "        \n",
    "        # Create a label encoder\n",
    "        label_encoder = LabelEncoder()\n",
    "        \n",
    "        # List for storing categorical indices\n",
    "        cat_indices = []\n",
    "        \n",
    "        # Iterate through each column\n",
    "        for i, col in enumerate(features):\n",
    "            if features[col].dtype == 'object':\n",
    "                # Map the categorical features to integers\n",
    "                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n",
    "                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n",
    "\n",
    "                # Record the categorical indices\n",
    "                cat_indices.append(i)\n",
    "    \n",
    "    # Catch error if label encoding scheme is not valid\n",
    "    else:\n",
    "        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n",
    "        \n",
    "    print('Training Data Shape: ', features.shape)\n",
    "    print('Testing Data Shape: ', test_features.shape)\n",
    "    \n",
    "    # Extract feature names\n",
    "    feature_names = list(features.columns)\n",
    "    \n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "    \n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = False, random_state = 50)\n",
    "    \n",
    "    # Empty array for feature importances\n",
    "    feature_importance_values = np.zeros(len(feature_names))\n",
    "    \n",
    "    # Empty array for test predictions\n",
    "    test_predictions = np.zeros(test_features.shape[0])\n",
    "    \n",
    "    # Empty array for out of fold validation predictions\n",
    "    out_of_fold = np.zeros(features.shape[0])\n",
    "    \n",
    "    # Lists for recording validation and training scores\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    \n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in k_fold.split(features):\n",
    "        \n",
    "        # Training data for the fold\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        # Validation data for the fold\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Create the model\n",
    "        model = lgb.LGBMClassifier(n_estimators=10000, objective = 'binary', \n",
    "                                   class_weight = 'balanced', learning_rate = 0.05, \n",
    "                                   reg_alpha = 0.1, reg_lambda = 0.1, \n",
    "                                   subsample = 0.8, n_jobs = -1, random_state = 50)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n",
    "                  early_stopping_rounds = 100, verbose = 200)\n",
    "        \n",
    "        # Record the best iteration\n",
    "        best_iteration = model.best_iteration_\n",
    "        \n",
    "        # Record the feature importances\n",
    "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n",
    "        \n",
    "        # Make predictions\n",
    "        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n",
    "        \n",
    "        # Record the out of fold predictions\n",
    "        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n",
    "        \n",
    "        # Record the best score\n",
    "        valid_score = model.best_score_['valid']['auc']\n",
    "        train_score = model.best_score_['train']['auc']\n",
    "        \n",
    "        valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "        \n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "        \n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n",
    "    \n",
    "    # Make the feature importance dataframe\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
    "    \n",
    "    # Overall validation score\n",
    "    valid_auc = roc_auc_score(labels, out_of_fold)\n",
    "    \n",
    "    # Add the overall scores to the metrics\n",
    "    valid_scores.append(valid_auc)\n",
    "    train_scores.append(np.mean(train_scores))\n",
    "    \n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "    \n",
    "    # Dataframe of validation scores\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            'valid': valid_scores}) \n",
    "    \n",
    "    return submission, feature_importances, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission, fi, metrics = model(features, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_manualp2.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
