{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Loading, Exploring, and Converting Dataset to Parquet Format**\n",
    "\n",
    "**Important Note**: The original `HomeCredit_columns_description.csv` file had a corrupted character at position 59, which prevented it from being read using UTF-8 encoding. **This character was manually corrected (removed and rewritten).**\n",
    "\n",
    "This notebook aims to achieve immediate performance improvements throughout the project, especially during the exploratory data analysis (EDA) and feature engineering phases. The primary objective is to convert the dataset from CSV to Parquet format, leveraging the significant benefits it offers in terms of reduced disk space usage and faster data loading. By conducting a comprehensive performance comparison between Parquet and CSV formats, we evaluate their efficiency in terms of read/write speed, disk space utilization, and data compression. Through this analysis, we identify the most suitable format that optimizes the dataset's performance characteristics.\n",
    "\n",
    "In this notebook, we begin by loading the dataset for the first time and providing an overview of its dimensions. Subsequently, a benchmark is performed to determine the optimal persistence method, with the ultimate goal of transitioning from CSV to Parquet format. Finally, the dataset is converted into the identified best Parquet format, striking a balance between disk footprint and loading time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading CSV files\n",
    "\n",
    "Alright, let's dive into the code! Our goal here is to load each table from the dataset and store them in a convenient dictionary format using dataframes. We'll go through all the CSV files located in a specified directory and measure the time it takes to load each table. The loaded dataframes will be organized within a dictionary, where each table is associated with a unique key. This approach allows us to easily access and manipulate the data. During the loading process, we'll display the table names, their respective shapes, and the time taken to load them. Finally, we'll also calculate and present the total time spent loading all the tables. Let's get started and load those tables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mapplication_test\u001b[0m: (48744, 121) - 523 ms, 602 mus\n",
      "\u001b[1mapplication_train\u001b[0m: (307511, 122) - 3 s, 262 ms\n",
      "\u001b[1mbureau\u001b[0m: (1716428, 17) - 2 s, 385 ms\n",
      "\u001b[1mbureau_balance\u001b[0m: (27299925, 3) - 4 s, 593 ms\n",
      "\u001b[1mcredit_card_balance\u001b[0m: (3840312, 23) - 7 s, 570 ms\n",
      "\u001b[1mHomeCredit_columns_description\u001b[0m: (219, 5) - 6 ms, 14 mus\n",
      "\u001b[1minstallments_payments\u001b[0m: (13605401, 8) - 10 s, 382 ms\n",
      "\u001b[1mPOS_CASH_balance\u001b[0m: (10001358, 8) - 5 s, 342 ms\n",
      "\u001b[1mprevious_application\u001b[0m: (1670214, 37) - 7 s, 247 ms\n",
      "\u001b[1msample_submission\u001b[0m: (48744, 2) - 15 ms, 990 mus\n",
      ">> \u001b[1mtotal read time\u001b[0m: 41 s, 329 ms\n"
     ]
    }
   ],
   "source": [
    "from pepper.persist import _get_filenames_glob  # Importing function to get CSV filenames\n",
    "from pepper.utils import pretty_timedelta_str, bold  # Importing utility functions\n",
    "import pandas as pd  # Importing pandas for data manipulation\n",
    "import time  # Importing time for measuring execution time\n",
    "\n",
    "csv_dir = \"../../dataset/csv/\"  # Directory path where CSV files are located\n",
    "filenames = _get_filenames_glob(csv_dir, \"csv\")  # Get list of CSV filenames\n",
    "\n",
    "data_dict = {}  # Dictionary to store dataframes\n",
    "read_times = []  # List to store loading times of each table\n",
    "\n",
    "for filename in filenames:\n",
    "    t = -time.time()  # Start measuring loading time\n",
    "    data_key = filename[:-4]  # Extract data key from filename\n",
    "    data = pd.read_csv(csv_dir + filename, encoding='utf-8')  # Read CSV file into a dataframe\n",
    "    t += time.time()  # Calculate elapsed time for loading\n",
    "    read_times.append(t)  # Store loading time in the list\n",
    "    data_dict[data_key] = data  # Add dataframe to the dictionary\n",
    "    # Display table name, shape, and loading time\n",
    "    print(f\"{bold(data_key)}: {data.shape} - {pretty_timedelta_str(t, 2)}\")\n",
    "\n",
    "# Display total read time for all tables\n",
    "print(f\">> {bold('total read time')}: {pretty_timedelta_str(sum(read_times), 2)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Overview\n",
    "\n",
    "In this section, we create a `metadata` dataframe that provides an overview of the dimensions of our dataset, which consists of multiple tables. This information can be useful for gaining insights into the structure and size of the dataset. We calculate the number of samples, number of features, and the total number of cells in each table. Additionally, we retrieve the size of each corresponding CSV file and add the CSV read times to the `metadata`. Finally, we sort the `metadata` dataframe by the number of cells in descending order and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mn_cells\u001b[0m: 493571166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_name</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_cells</th>\n",
       "      <th>csv_size</th>\n",
       "      <th>csv_read_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>installments_payments</td>\n",
       "      <td>13605401</td>\n",
       "      <td>8</td>\n",
       "      <td>108843208</td>\n",
       "      <td>723118349</td>\n",
       "      <td>10.382170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>credit_card_balance</td>\n",
       "      <td>3840312</td>\n",
       "      <td>23</td>\n",
       "      <td>88327176</td>\n",
       "      <td>424582605</td>\n",
       "      <td>7.570210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bureau_balance</td>\n",
       "      <td>27299925</td>\n",
       "      <td>3</td>\n",
       "      <td>81899775</td>\n",
       "      <td>375592889</td>\n",
       "      <td>4.593670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>POS_CASH_balance</td>\n",
       "      <td>10001358</td>\n",
       "      <td>8</td>\n",
       "      <td>80010864</td>\n",
       "      <td>392703158</td>\n",
       "      <td>5.342954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>previous_application</td>\n",
       "      <td>1670214</td>\n",
       "      <td>37</td>\n",
       "      <td>61797918</td>\n",
       "      <td>404973293</td>\n",
       "      <td>7.247273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>application_train</td>\n",
       "      <td>307511</td>\n",
       "      <td>122</td>\n",
       "      <td>37516342</td>\n",
       "      <td>166133370</td>\n",
       "      <td>3.262308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bureau</td>\n",
       "      <td>1716428</td>\n",
       "      <td>17</td>\n",
       "      <td>29179276</td>\n",
       "      <td>170016717</td>\n",
       "      <td>2.385545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>application_test</td>\n",
       "      <td>48744</td>\n",
       "      <td>121</td>\n",
       "      <td>5898024</td>\n",
       "      <td>26567651</td>\n",
       "      <td>0.523602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sample_submission</td>\n",
       "      <td>48744</td>\n",
       "      <td>2</td>\n",
       "      <td>97488</td>\n",
       "      <td>536202</td>\n",
       "      <td>0.015990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HomeCredit_columns_description</td>\n",
       "      <td>219</td>\n",
       "      <td>5</td>\n",
       "      <td>1095</td>\n",
       "      <td>37391</td>\n",
       "      <td>0.006014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       table_name  n_samples  n_features    n_cells   \n",
       "6           installments_payments   13605401           8  108843208  \\\n",
       "4             credit_card_balance    3840312          23   88327176   \n",
       "3                  bureau_balance   27299925           3   81899775   \n",
       "7                POS_CASH_balance   10001358           8   80010864   \n",
       "8            previous_application    1670214          37   61797918   \n",
       "1               application_train     307511         122   37516342   \n",
       "2                          bureau    1716428          17   29179276   \n",
       "0                application_test      48744         121    5898024   \n",
       "9               sample_submission      48744           2      97488   \n",
       "5  HomeCredit_columns_description        219           5       1095   \n",
       "\n",
       "    csv_size  csv_read_time  \n",
       "6  723118349      10.382170  \n",
       "4  424582605       7.570210  \n",
       "3  375592889       4.593670  \n",
       "7  392703158       5.342954  \n",
       "8  404973293       7.247273  \n",
       "1  166133370       3.262308  \n",
       "2  170016717       2.385545  \n",
       "0   26567651       0.523602  \n",
       "9     536202       0.015990  \n",
       "5      37391       0.006014  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from pepper.utils import bold\n",
    "from pepper.utils import get_file_size\n",
    "import pandas as pd\n",
    "\n",
    "# Create metadata dataframe to provide an overview of the dataset dimensions\n",
    "metadata = pd.DataFrame(\n",
    "    [(key, *data.shape) for key, data in data_dict.items()],\n",
    "    columns=[\"table_name\", \"n_samples\", \"n_features\"]\n",
    ")\n",
    "\n",
    "# Calculate the total number of cells in each table\n",
    "metadata[\"n_cells\"] = metadata.n_samples * metadata.n_features\n",
    "\n",
    "# Retrieve the size of each CSV file\n",
    "metadata[\"csv_size\"] = metadata.table_name.apply(\n",
    "    lambda x: get_file_size(csv_dir + x + \".csv\")\n",
    ")\n",
    "\n",
    "# Add CSV read times to the metadata dataframe\n",
    "metadata[\"csv_read_time\"] = read_times\n",
    "\n",
    "# Sort the metadata dataframe by the number of cells in descending order\n",
    "metadata = metadata.sort_values(by=\"n_cells\", ascending=False)\n",
    "\n",
    "# Print the total number of cells in the dataset using bold formatting\n",
    "print(f\"{bold('n_cells')}: {metadata.n_cells.sum()}\")\n",
    "\n",
    "# Display the metadata dataframe\n",
    "display(metadata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark: Saving Dataset to Parquet with Various Configurations\n",
    "\n",
    "When saving the dataset in the Parquet format, the default configuration uses the `pyarrow` engine for processing. If `pyarrow` is not available, it falls back to using the `fastparquet` engine. The data is compressed using the `snappy` compression algorithm.\n",
    "\n",
    "Our goal is to compare the performance in terms of disk memory usage and loading time for six possible configurations. These configurations depend on the choice of engine (`pyarrow` or `fastparquet`) and compression (`snappy`, `gzip`, `brotli`, or no compression).\n",
    "\n",
    "For each configuration, we create a dedicated subdirectory to store the Parquet files. The dataset is then saved to Parquet using the specified engine and compression. The progress of the operation is displayed, indicating the configuration and the time taken.\n",
    "\n",
    "Please note that we have excluded the combination of `fastparquet` engine with `brotli` compression due to an unidentified issue that causes the execution to enter an infinite loop.\n",
    "\n",
    "**Warning**: If you plan to rerun this benchmark, please allocate approximately 10 minutes for the execution.\n",
    "\n",
    "**Further readings**:\n",
    "* [**`pandas.DataFrame.to_parquet`** documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html)\n",
    "* [**Stack Overflow**: Python - Save pandas data frame to Parquet file](https://stackoverflow.com/questions/41066582/python-save-pandas-data-frame-to-parquet-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset to ../../dataset/pqt/pyarrow_snappy/.......... in 25 s, 799 ms\n",
      "Saving dataset to ../../dataset/pqt/pyarrow_gzip/.......... in 2 m, 18 s\n",
      "Saving dataset to ../../dataset/pqt/pyarrow_brotli/.......... in 2 m, 16 s\n",
      "Saving dataset to ../../dataset/pqt/pyarrow_none/.......... in 24 s, 126 ms\n",
      "Saving dataset to ../../dataset/pqt/fastparquet_snappy/.......... in 26 s, 533 ms\n",
      "Saving dataset to ../../dataset/pqt/fastparquet_gzip/.......... in 3 m, 6 s\n",
      "Saving dataset to ../../dataset/pqt/fastparquet_none/.......... in 24 s, 195 ms\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from pepper.persist import all_to_parquet\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "# Define CSV and Parquet directories\n",
    "csv_dir = \"../../dataset/csv/\"\n",
    "pqt_dir = \"../../dataset/pqt/\"\n",
    "\n",
    "# Define the list of engines and compressions to test\n",
    "engines = [\"pyarrow\", \"fastparquet\"]\n",
    "compressions = [\"snappy\", \"gzip\", \"brotli\", None]\n",
    "\n",
    "# Iterate over all combinations of engines and compressions\n",
    "for engine, compression in itertools.product(engines, compressions):\n",
    "    # Skip the combination of fastparquet and brotli due to an unidentified issue\n",
    "    if engine == \"fastparquet\" and compression == \"brotli\":\n",
    "        continue\n",
    "    \n",
    "    # Create a configuration name based on the engine and compression\n",
    "    config_name = f\"{engine}_{str(compression).lower()}\"\n",
    "    \n",
    "    # Define the subdirectory for the Parquet files\n",
    "    pqt_subdir = pqt_dir + config_name + \"/\"\n",
    "    \n",
    "    # Measure the time taken to save the dataset to Parquet\n",
    "    t = -time.time()\n",
    "    print(f\"Saving dataset to {pqt_subdir}\", end=\"\")\n",
    "    all_to_parquet(data_dict, pqt_subdir, engine, compression)\n",
    "    t += time.time()\n",
    "    print(f\" in {pretty_timedelta_str(t, 2)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Comparison: Parquet vs CSV Formats\n",
    "\n",
    "The objective here is to compare the performance of the different configurations (engines and compressions) when reading Parquet files."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each combination of engine and compression, we measure the _file size_ and _read time_ for each table in the `metadata` dataframe. The measurements are stored in the `metadata` dataframe for further analysis and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_name</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_cells</th>\n",
       "      <th>csv_size</th>\n",
       "      <th>csv_read_time</th>\n",
       "      <th>pqt_pyarrow_snappy_size</th>\n",
       "      <th>pqt_pyarrow_snappy_read_time</th>\n",
       "      <th>pqt_pyarrow_gzip_size</th>\n",
       "      <th>pqt_pyarrow_gzip_read_time</th>\n",
       "      <th>pqt_pyarrow_brotli_size</th>\n",
       "      <th>pqt_pyarrow_brotli_read_time</th>\n",
       "      <th>pqt_pyarrow_none_size</th>\n",
       "      <th>pqt_pyarrow_none_read_time</th>\n",
       "      <th>pqt_fastparquet_snappy_size</th>\n",
       "      <th>pqt_fastparquet_snappy_read_time</th>\n",
       "      <th>pqt_fastparquet_gzip_size</th>\n",
       "      <th>pqt_fastparquet_gzip_read_time</th>\n",
       "      <th>pqt_fastparquet_none_size</th>\n",
       "      <th>pqt_fastparquet_none_read_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>installments_payments</td>\n",
       "      <td>13605401</td>\n",
       "      <td>8</td>\n",
       "      <td>108843208</td>\n",
       "      <td>723118349</td>\n",
       "      <td>10.382170</td>\n",
       "      <td>330470104</td>\n",
       "      <td>3.219193</td>\n",
       "      <td>246648550</td>\n",
       "      <td>1.621335</td>\n",
       "      <td>234206927</td>\n",
       "      <td>1.731876</td>\n",
       "      <td>478259694</td>\n",
       "      <td>1.064058</td>\n",
       "      <td>417551342</td>\n",
       "      <td>2.224942</td>\n",
       "      <td>273744883</td>\n",
       "      <td>1.681106</td>\n",
       "      <td>874103290</td>\n",
       "      <td>1.536755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>credit_card_balance</td>\n",
       "      <td>3840312</td>\n",
       "      <td>23</td>\n",
       "      <td>88327176</td>\n",
       "      <td>424582605</td>\n",
       "      <td>7.570210</td>\n",
       "      <td>111274155</td>\n",
       "      <td>1.300946</td>\n",
       "      <td>87382864</td>\n",
       "      <td>1.310590</td>\n",
       "      <td>84062930</td>\n",
       "      <td>1.254331</td>\n",
       "      <td>231893301</td>\n",
       "      <td>1.012982</td>\n",
       "      <td>158525573</td>\n",
       "      <td>1.203214</td>\n",
       "      <td>99998309</td>\n",
       "      <td>1.233918</td>\n",
       "      <td>671997342</td>\n",
       "      <td>1.389169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bureau_balance</td>\n",
       "      <td>27299925</td>\n",
       "      <td>3</td>\n",
       "      <td>81899775</td>\n",
       "      <td>375592889</td>\n",
       "      <td>4.593670</td>\n",
       "      <td>21426895</td>\n",
       "      <td>2.538228</td>\n",
       "      <td>7220080</td>\n",
       "      <td>2.998022</td>\n",
       "      <td>6528751</td>\n",
       "      <td>2.655512</td>\n",
       "      <td>212427359</td>\n",
       "      <td>2.393628</td>\n",
       "      <td>39104894</td>\n",
       "      <td>2.044033</td>\n",
       "      <td>8773070</td>\n",
       "      <td>1.879325</td>\n",
       "      <td>573299674</td>\n",
       "      <td>2.351481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>POS_CASH_balance</td>\n",
       "      <td>10001358</td>\n",
       "      <td>8</td>\n",
       "      <td>80010864</td>\n",
       "      <td>392703158</td>\n",
       "      <td>5.342954</td>\n",
       "      <td>124435906</td>\n",
       "      <td>1.242508</td>\n",
       "      <td>89478858</td>\n",
       "      <td>1.522190</td>\n",
       "      <td>84330013</td>\n",
       "      <td>1.436072</td>\n",
       "      <td>192425645</td>\n",
       "      <td>1.203197</td>\n",
       "      <td>166379319</td>\n",
       "      <td>1.406085</td>\n",
       "      <td>93648196</td>\n",
       "      <td>1.318370</td>\n",
       "      <td>664506876</td>\n",
       "      <td>1.580753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>previous_application</td>\n",
       "      <td>1670214</td>\n",
       "      <td>37</td>\n",
       "      <td>61797918</td>\n",
       "      <td>404973293</td>\n",
       "      <td>7.247273</td>\n",
       "      <td>62912447</td>\n",
       "      <td>2.056663</td>\n",
       "      <td>49908242</td>\n",
       "      <td>2.102959</td>\n",
       "      <td>48304590</td>\n",
       "      <td>1.969963</td>\n",
       "      <td>80714342</td>\n",
       "      <td>1.791365</td>\n",
       "      <td>115293797</td>\n",
       "      <td>1.773969</td>\n",
       "      <td>62131222</td>\n",
       "      <td>1.770063</td>\n",
       "      <td>514893753</td>\n",
       "      <td>1.924712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>application_train</td>\n",
       "      <td>307511</td>\n",
       "      <td>122</td>\n",
       "      <td>37516342</td>\n",
       "      <td>166133370</td>\n",
       "      <td>3.262308</td>\n",
       "      <td>22225869</td>\n",
       "      <td>0.517867</td>\n",
       "      <td>18770994</td>\n",
       "      <td>0.567186</td>\n",
       "      <td>18486431</td>\n",
       "      <td>0.455677</td>\n",
       "      <td>24879919</td>\n",
       "      <td>0.505942</td>\n",
       "      <td>49802974</td>\n",
       "      <td>0.458047</td>\n",
       "      <td>25306399</td>\n",
       "      <td>0.482109</td>\n",
       "      <td>253550609</td>\n",
       "      <td>0.560997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bureau</td>\n",
       "      <td>1716428</td>\n",
       "      <td>17</td>\n",
       "      <td>29179276</td>\n",
       "      <td>170016717</td>\n",
       "      <td>2.385545</td>\n",
       "      <td>35241265</td>\n",
       "      <td>0.518472</td>\n",
       "      <td>25883443</td>\n",
       "      <td>0.500996</td>\n",
       "      <td>24365040</td>\n",
       "      <td>0.473197</td>\n",
       "      <td>61232824</td>\n",
       "      <td>0.510756</td>\n",
       "      <td>52235506</td>\n",
       "      <td>0.479927</td>\n",
       "      <td>29284991</td>\n",
       "      <td>0.481600</td>\n",
       "      <td>234062490</td>\n",
       "      <td>0.584300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>application_test</td>\n",
       "      <td>48744</td>\n",
       "      <td>121</td>\n",
       "      <td>5898024</td>\n",
       "      <td>26567651</td>\n",
       "      <td>0.523602</td>\n",
       "      <td>4255523</td>\n",
       "      <td>0.099171</td>\n",
       "      <td>3596498</td>\n",
       "      <td>0.096352</td>\n",
       "      <td>3505436</td>\n",
       "      <td>0.087762</td>\n",
       "      <td>4861820</td>\n",
       "      <td>0.097831</td>\n",
       "      <td>8361289</td>\n",
       "      <td>0.083632</td>\n",
       "      <td>4258899</td>\n",
       "      <td>0.094115</td>\n",
       "      <td>40157544</td>\n",
       "      <td>0.108442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sample_submission</td>\n",
       "      <td>48744</td>\n",
       "      <td>2</td>\n",
       "      <td>97488</td>\n",
       "      <td>536202</td>\n",
       "      <td>0.015990</td>\n",
       "      <td>296358</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>170995</td>\n",
       "      <td>0.012058</td>\n",
       "      <td>156444</td>\n",
       "      <td>0.019707</td>\n",
       "      <td>489947</td>\n",
       "      <td>0.023255</td>\n",
       "      <td>215625</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>77364</td>\n",
       "      <td>0.012637</td>\n",
       "      <td>780849</td>\n",
       "      <td>0.013176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HomeCredit_columns_description</td>\n",
       "      <td>219</td>\n",
       "      <td>5</td>\n",
       "      <td>1095</td>\n",
       "      <td>37391</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>13372</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>10505</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>9931</td>\n",
       "      <td>0.011017</td>\n",
       "      <td>23605</td>\n",
       "      <td>0.009794</td>\n",
       "      <td>10992</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>7179</td>\n",
       "      <td>0.015567</td>\n",
       "      <td>41639</td>\n",
       "      <td>0.008494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       table_name  n_samples  n_features    n_cells   \n",
       "6           installments_payments   13605401           8  108843208  \\\n",
       "4             credit_card_balance    3840312          23   88327176   \n",
       "3                  bureau_balance   27299925           3   81899775   \n",
       "7                POS_CASH_balance   10001358           8   80010864   \n",
       "8            previous_application    1670214          37   61797918   \n",
       "1               application_train     307511         122   37516342   \n",
       "2                          bureau    1716428          17   29179276   \n",
       "0                application_test      48744         121    5898024   \n",
       "9               sample_submission      48744           2      97488   \n",
       "5  HomeCredit_columns_description        219           5       1095   \n",
       "\n",
       "    csv_size  csv_read_time  pqt_pyarrow_snappy_size   \n",
       "6  723118349      10.382170                330470104  \\\n",
       "4  424582605       7.570210                111274155   \n",
       "3  375592889       4.593670                 21426895   \n",
       "7  392703158       5.342954                124435906   \n",
       "8  404973293       7.247273                 62912447   \n",
       "1  166133370       3.262308                 22225869   \n",
       "2  170016717       2.385545                 35241265   \n",
       "0   26567651       0.523602                  4255523   \n",
       "9     536202       0.015990                   296358   \n",
       "5      37391       0.006014                    13372   \n",
       "\n",
       "   pqt_pyarrow_snappy_read_time  pqt_pyarrow_gzip_size   \n",
       "6                      3.219193              246648550  \\\n",
       "4                      1.300946               87382864   \n",
       "3                      2.538228                7220080   \n",
       "7                      1.242508               89478858   \n",
       "8                      2.056663               49908242   \n",
       "1                      0.517867               18770994   \n",
       "2                      0.518472               25883443   \n",
       "0                      0.099171                3596498   \n",
       "9                      0.015504                 170995   \n",
       "5                      0.010037                  10505   \n",
       "\n",
       "   pqt_pyarrow_gzip_read_time  pqt_pyarrow_brotli_size   \n",
       "6                    1.621335                234206927  \\\n",
       "4                    1.310590                 84062930   \n",
       "3                    2.998022                  6528751   \n",
       "7                    1.522190                 84330013   \n",
       "8                    2.102959                 48304590   \n",
       "1                    0.567186                 18486431   \n",
       "2                    0.500996                 24365040   \n",
       "0                    0.096352                  3505436   \n",
       "9                    0.012058                   156444   \n",
       "5                    0.009007                     9931   \n",
       "\n",
       "   pqt_pyarrow_brotli_read_time  pqt_pyarrow_none_size   \n",
       "6                      1.731876              478259694  \\\n",
       "4                      1.254331              231893301   \n",
       "3                      2.655512              212427359   \n",
       "7                      1.436072              192425645   \n",
       "8                      1.969963               80714342   \n",
       "1                      0.455677               24879919   \n",
       "2                      0.473197               61232824   \n",
       "0                      0.087762                4861820   \n",
       "9                      0.019707                 489947   \n",
       "5                      0.011017                  23605   \n",
       "\n",
       "   pqt_pyarrow_none_read_time  pqt_fastparquet_snappy_size   \n",
       "6                    1.064058                    417551342  \\\n",
       "4                    1.012982                    158525573   \n",
       "3                    2.393628                     39104894   \n",
       "7                    1.203197                    166379319   \n",
       "8                    1.791365                    115293797   \n",
       "1                    0.505942                     49802974   \n",
       "2                    0.510756                     52235506   \n",
       "0                    0.097831                      8361289   \n",
       "9                    0.023255                       215625   \n",
       "5                    0.009794                        10992   \n",
       "\n",
       "   pqt_fastparquet_snappy_read_time  pqt_fastparquet_gzip_size   \n",
       "6                          2.224942                  273744883  \\\n",
       "4                          1.203214                   99998309   \n",
       "3                          2.044033                    8773070   \n",
       "7                          1.406085                   93648196   \n",
       "8                          1.773969                   62131222   \n",
       "1                          0.458047                   25306399   \n",
       "2                          0.479927                   29284991   \n",
       "0                          0.083632                    4258899   \n",
       "9                          0.012600                      77364   \n",
       "5                          0.009524                       7179   \n",
       "\n",
       "   pqt_fastparquet_gzip_read_time  pqt_fastparquet_none_size   \n",
       "6                        1.681106                  874103290  \\\n",
       "4                        1.233918                  671997342   \n",
       "3                        1.879325                  573299674   \n",
       "7                        1.318370                  664506876   \n",
       "8                        1.770063                  514893753   \n",
       "1                        0.482109                  253550609   \n",
       "2                        0.481600                  234062490   \n",
       "0                        0.094115                   40157544   \n",
       "9                        0.012637                     780849   \n",
       "5                        0.015567                      41639   \n",
       "\n",
       "   pqt_fastparquet_none_read_time  \n",
       "6                        1.536755  \n",
       "4                        1.389169  \n",
       "3                        2.351481  \n",
       "7                        1.580753  \n",
       "8                        1.924712  \n",
       "1                        0.560997  \n",
       "2                        0.584300  \n",
       "0                        0.108442  \n",
       "9                        0.013176  \n",
       "5                        0.008494  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pepper.utils import get_file_size\n",
    "\n",
    "# Function to measure the time taken to read a Parquet file\n",
    "def pqt_read_time(pqt_dir, table_name):\n",
    "    t = time.time()\n",
    "    pd.read_parquet(pqt_dir + table_name + \".pqt\")\n",
    "    return time.time() - t\n",
    "\n",
    "# Function to get the file size of a Parquet file\n",
    "def pqt_file_size(pqt_dir, table_name):\n",
    "    return get_file_size(pqt_dir + table_name + \".pqt\")\n",
    "\n",
    "# List of engines and compressions to iterate over\n",
    "engines = [\"pyarrow\", \"fastparquet\"]\n",
    "compressions = [\"snappy\", \"gzip\", \"brotli\", None]\n",
    "\n",
    "# Iterate over all combinations of engines and compressions\n",
    "for engine, compression in itertools.product(engines, compressions):\n",
    "    # Skip the combination of fastparquet and brotli\n",
    "    if engine == \"fastparquet\" and compression == \"brotli\":\n",
    "        continue\n",
    "    config_name = f\"{engine}_{str(compression).lower()}\"\n",
    "    pqt_subdir = pqt_dir + config_name + \"/\"\n",
    "    \n",
    "    # Calculate and store the file size for each table using the specified engine and compression\n",
    "    metadata[f\"pqt_{config_name}_size\"] = metadata.table_name.apply(\n",
    "        lambda x: pqt_file_size(pqt_subdir, x)\n",
    "    )\n",
    "    \n",
    "    # Measure and store the read time for each table using the specified engine and compression\n",
    "    metadata[f\"pqt_{config_name}_read_time\"] = metadata.table_name.apply(\n",
    "        lambda x: pqt_read_time(pqt_subdir, x)\n",
    "    )\n",
    "\n",
    "# Display the updated metadata dataframe\n",
    "display(metadata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the summary below, the best choice seems to be `pyarrow` + `gzip`.\n",
    "\n",
    "This is the default configuration that we have settled on.\n",
    "\n",
    "It provides a 5x improvement in both speed and disk footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "table_name                          installments_paymentscredit_card_balancebureau...\n",
       "n_samples                                                                    58538856\n",
       "n_features                                                                        346\n",
       "n_cells                                                                     493571166\n",
       "csv_size                                                                   2684261625\n",
       "csv_read_time                                                               41.329736\n",
       "pqt_pyarrow_snappy_size                                                     712551894\n",
       "pqt_pyarrow_snappy_read_time                                                11.518589\n",
       "pqt_pyarrow_gzip_size                                                       529071029\n",
       "pqt_pyarrow_gzip_read_time                                                  10.740693\n",
       "pqt_pyarrow_brotli_size                                                     503956493\n",
       "pqt_pyarrow_brotli_read_time                                                10.095113\n",
       "pqt_pyarrow_none_size                                                      1287208456\n",
       "pqt_pyarrow_none_read_time                                                   8.612808\n",
       "pqt_fastparquet_snappy_size                                                1007481311\n",
       "pqt_fastparquet_snappy_read_time                                             9.695972\n",
       "pqt_fastparquet_gzip_size                                                   597230512\n",
       "pqt_fastparquet_gzip_read_time                                               8.968808\n",
       "pqt_fastparquet_none_size                                                  3827394066\n",
       "pqt_fastparquet_none_read_time                                               10.05828\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the sum of each column in the `metadata` DataFrame\n",
    "display(metadata.sum(axis=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a *pretty* table to present these results on presentation slides (the Markdown table can be copied to the clipboard).\n",
    "\n",
    "The code snippet below takes the `metadata` DataFrame, selects the desired columns for the resulting table, and creates a copy of it. It then calculates the total values for each column and assigns them to the \"TOTAL\" row. Next, it applies formatting functions to specific columns to format file sizes, time durations, and large integers. The column names are modified for better readability. Finally, the formatted table is displayed using the `display_dataframe_in_markdown` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|table name|#samples|#features|#cells|csv size|csv readtime|parquet size|parquet readtime|\n",
       "|-|-|-|-|-|-|-|-|\n",
       "|installments_payments|13 605 401|8|108 843 208|689.6 MiB|10 s|235.2 MiB|1 s|\n",
       "|credit_card_balance|3 840 312|23|88 327 176|404.9 MiB|7 s|83.3 MiB|1 s|\n",
       "|bureau_balance|27 299 925|3|81 899 775|358.2 MiB|4 s|6.9 MiB|2 s|\n",
       "|POS_CASH_balance|10 001 358|8|80 010 864|374.5 MiB|5 s|85.3 MiB|1 s|\n",
       "|previous_application|1 670 214|37|61 797 918|386.2 MiB|7 s|47.6 MiB|2 s|\n",
       "|application_train|307 511|122|37 516 342|158.4 MiB|3 s|17.9 MiB|567 ms|\n",
       "|bureau|1 716 428|17|29 179 276|162.1 MiB|2 s|24.7 MiB|500 ms|\n",
       "|application_test|48 744|121|5 898 024|25.3 MiB|523 ms|3.4 MiB|96 ms|\n",
       "|sample_submission|48 744|2|97 488|523.6 KiB|15 ms|167.0 KiB|12 ms|\n",
       "|HomeCredit_columns_description|219|5|1 095|36.5 KiB|6 ms|10.3 KiB|9 ms|\n",
       "|****TOTAL****|**58 538 856**|**346**|**493 571 166**|**2.5 GiB**|**41 s**|**504.6 MiB**|**10 s**|"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pepper.utils import display_dataframe_in_markdown, format_iB, pretty_timedelta_str\n",
    "\n",
    "# Function to format file size\n",
    "def format_size(x):\n",
    "    sz, unity = format_iB(x)\n",
    "    return f\"{sz:.1f} {unity}\"\n",
    "\n",
    "# Function to format time duration\n",
    "def format_time(x):\n",
    "    return pretty_timedelta_str(x, 1)\n",
    "\n",
    "# Function to format large integers with thousand separators\n",
    "def format_bigint(x):\n",
    "    return f\"{x:n}\"\n",
    "\n",
    "# Get the columns from the metadata DataFrame\n",
    "cols = metadata.columns\n",
    "\n",
    "# Select the desired columns for the resulting table\n",
    "res_cols = list(cols[:6]) + list(cols[cols.str.contains(\"pyarrow_gzip\")])\n",
    "res = metadata[res_cols]\n",
    "\n",
    "# Create a copy of the resulting table\n",
    "res_2 = res.copy()\n",
    "\n",
    "# Calculate the total values for each column and assign it to the \"TOTAL\" row\n",
    "total = res_2.sum(axis=0)\n",
    "total[0] = \"**TOTAL**\"\n",
    "res_2.loc[\"TOTAL\"] = total\n",
    "\n",
    "# Apply formatting functions to specific columns\n",
    "res_2.csv_size = res_2.csv_size.apply(format_size)\n",
    "res_2.pqt_pyarrow_gzip_size = res_2.pqt_pyarrow_gzip_size.apply(format_size)\n",
    "res_2.csv_read_time = res_2.csv_read_time.apply(format_time)\n",
    "res_2.pqt_pyarrow_gzip_read_time = res_2.pqt_pyarrow_gzip_read_time.apply(format_time)\n",
    "res_2.n_samples = res_2.n_samples.apply(format_bigint)\n",
    "res_2.n_cells = res_2.n_cells.apply(format_bigint)\n",
    "\n",
    "# Modify column names for better readability\n",
    "res_2.columns = (\n",
    "    res_2.columns\n",
    "    .str.replace(\"n_\", \"#\")\n",
    "    .str.replace(\"pqt_pyarrow_gzip\", \"parquet\")\n",
    "    .str.replace(\"read_time\", \"readtime\")\n",
    "    .str.replace(\"_\", \" \")\n",
    ")\n",
    "\n",
    "# Format the \"TOTAL\" row to be displayed in bold\n",
    "res_2.loc[\"TOTAL\"] = res_2.loc[\"TOTAL\"].apply(lambda x: f\"**{x}**\")\n",
    "\n",
    "# Display the formatted table in Markdown format\n",
    "display_dataframe_in_markdown(res_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrieve the files generated in the `pyarrow` + `gzip` configuration and move them to the parent directory `dataset/pqt/` for safekeeping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application_test.pqt\n",
      "application_train.pqt\n",
      "bureau.pqt\n",
      "bureau_balance.pqt\n",
      "credit_card_balance.pqt\n",
      "HomeCredit_columns_description.pqt\n",
      "installments_payments.pqt\n",
      "POS_CASH_balance.pqt\n",
      "previous_application.pqt\n",
      "sample_submission.pqt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "def move_files_to_parent(dir_path):\n",
    "    \"\"\"Moves all files in the specified directory to its parent directory.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dir_path (str):\n",
    "        The path to the directory containing the files.\n",
    "    \"\"\"\n",
    "    parent_dir_path = Path(dir_path).parent\n",
    "    for file in Path(dir_path).iterdir():\n",
    "        print(file.name)\n",
    "        file.rename(parent_dir_path.joinpath(file.name))\n",
    "\n",
    "pqt_subdir = \"../../dataset/pqt/pyarrow_gzip/\"\n",
    "move_files_to_parent(pqt_subdir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's free up disk space by removing the files in the other parquet formats generated during our benchmark (because life is all about taking risks, right?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "def _dangerous_rmtree_all_subdirs(dir_path):\n",
    "    \"\"\"Recursively removes all subdirectories and their contents within the specified directory.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dir_path (str):\n",
    "        The path to the directory to be removed.\n",
    "    \"\"\"\n",
    "    for child_name in os.listdir(dir_path):\n",
    "        child_path = os.path.join(dir_path, child_name)\n",
    "        if os.path.isdir(child_path):\n",
    "            shutil.rmtree(child_path)\n",
    "\n",
    "pqt_dir = \"../../dataset/pqt\"\n",
    "_dangerous_rmtree_all_subdirs(pqt_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
