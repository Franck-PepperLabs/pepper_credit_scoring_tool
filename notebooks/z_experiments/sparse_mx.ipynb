{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le point sur les **Matrices creuses**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dans le cadre de HomeCredit, le nombre de variables catégorielle à hot encoder est important. De même, les détails des balances mensuelles par client s'étalent sur 96 mois qu'il s'agit de mettre en colonnes à l'aide d'un pivot. Ajoutons à cela le feature engineering avec ses variables additionnelles, peut-être quelques expansions polynomiales ici et là : je vais me retrouver avec beaucoup de colonnes avant de procéder à ma normalisation et ma réduction de dimensionnalité.*\n",
    "\n",
    "*Ma question porte sur les matrices creuses. Ils me semble qu'elles répondent exactement à ce type de problématique, mais il me semble qu'elles font partie de Scipy et ne font pas forcément bon ménage avec Pandas ou Scikitlearn.*\n",
    "\n",
    "*Que peux-tu m'en dire en synthèse, comment les utiliser dans le contexte que je viens de te décrire, si possible avec quelques exemples de code illustratifs ?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectivement, les matrices creuses peuvent être très utiles dans le cas de datasets contenant un grand nombre de variables, mais où la majorité des valeurs sont nulles. Dans ce cas, il est souvent plus efficace d'utiliser des matrices creuses plutôt que des matrices denses, car les matrices creuses ne stockent que les valeurs non nulles, ce qui permet de réduire considérablement la mémoire nécessaire pour stocker les données.\n",
    "\n",
    "Les matrices creuses sont disponibles dans la bibliothèque Scipy, et peuvent être converties en objets Pandas ou Numpy si besoin. Il est également possible d'utiliser des matrices creuses avec Scikit-learn en utilisant la classe `sparse.csr_matrix`.\n",
    "\n",
    "Voici un exemple de conversion d'une matrice Pandas dense en une matrice Scipy creuse :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Création d'une matrice Pandas dense\n",
    "df = pd.DataFrame({'col1': [1, 0, 0, 2], 'col2': [0, 3, 0, 0], 'col3': [4, 0, 5, 0]})\n",
    "\n",
    "# Conversion en matrice Scipy creuse\n",
    "sparse_matrix = csr_matrix(df.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser une matrice creuse avec Scikit-learn, vous pouvez simplement fournir la matrice creuse à la fonction ou à l'estimateur approprié. Voici un exemple de transformation PCA utilisant une matrice creuse :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PCA does not support sparse input. See TruncatedSVD for a possible alternative.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39m# Réduction de la dimensionnalité avec PCA\u001b[39;00m\n\u001b[0;32m      8\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m reduced_sparse_matrix \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39;49mfit_transform(sparse_matrix)\n",
      "File \u001b[1;32mc:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:462\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \n\u001b[0;32m    441\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mC-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 462\u001b[0m U, S, Vt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[0;32m    463\u001b[0m U \u001b[39m=\u001b[39m U[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components_]\n\u001b[0;32m    465\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhiten:\n\u001b[0;32m    466\u001b[0m     \u001b[39m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:480\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39m# Raise an error for sparse input.\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \u001b[39m# This is more informative than the generic one raised by check_array.\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[1;32m--> 480\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPCA does not support sparse input. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTruncatedSVD for a possible alternative.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m     )\n\u001b[0;32m    485\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m    486\u001b[0m     X, dtype\u001b[39m=\u001b[39m[np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32], ensure_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, copy\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[0;32m    487\u001b[0m )\n\u001b[0;32m    489\u001b[0m \u001b[39m# Handle n_components==None\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: PCA does not support sparse input. See TruncatedSVD for a possible alternative."
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Création d'une matrice Scipy creuse\n",
    "sparse_matrix = csr_matrix(df.values)\n",
    "\n",
    "# Réduction de la dimensionnalité avec PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_sparse_matrix = pca.fit_transform(sparse_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Quand chat racconte des cracks..* :\n",
    "* TypeError: PCA does not support sparse input. See TruncatedSVD for a possible alternative.\n",
    "* https://stackoverflow.com/questions/33603787/performing-pca-on-large-sparse-matrix-by-using-sklearn\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, pour créer des matrices creuses à partir de données textuelles, vous pouvez utiliser la fonction `CountVectorizer` de Scikit-learn. Cette fonction crée une matrice creuse contenant les comptages de chaque mot dans le corpus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Création d'un corpus de textes\n",
    "corpus = ['Ce texte contient des mots.', 'Ce texte aussi.', 'Ce texte est différent des autres.']\n",
    "\n",
    "# Vectorisation des textes en matrice creuse\n",
    "vectorizer = CountVectorizer()\n",
    "sparse_matrix = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En résumé, les matrices creuses sont très utiles pour travailler avec des datasets contenant un grand nombre de variables, et leur utilisation est assez simple avec Scipy, Pandas et Scikit-learn. N'hésitez pas à les utiliser pour optimiser l'utilisation de la mémoire et améliorer les performances de votre modèle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ok, merci beaucoup. Sous-question : si dans mon jeu de données, j'ai des sections (des sous-ensemble de variables) denses, et d'autres creuses, comment je fais : tout dense, tout creux, ou existe-t-il un moyen hybride ?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oui, il est possible d'utiliser des matrices creuses pour les sections creuses et des matrices denses pour les sections denses, et ensuite les concaténer en une seule matrice.\n",
    "\n",
    "Par exemple, si vous avez une matrice dense `X_dense` et une matrice creuse `X_sparse`, vous pouvez les concaténer horizontalement (c.-à-d. ajouter des colonnes) en utilisant la fonction `hstack` de la bibliothèque `scipy.sparse` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# X_dense : matrice dense\n",
    "# X_sparse : matrice creuse\n",
    "X = hstack([X_sparse, X_dense])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec cette méthode, vous pouvez garder les parties denses et creuses de votre jeu de données séparées, tout en les combinant en une seule matrice.\n",
    "\n",
    "Il est également possible de créer des matrices creuses à partir de matrices denses et vice versa en utilisant les fonctions de conversion de `scipy.sparse`. Par exemple, pour convertir une matrice dense en matrice creuse, vous pouvez utiliser la fonction `csr_matrix` de `scipy.sparse` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# X_dense : matrice dense\n",
    "X_sparse = csr_matrix(X_dense)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et pour convertir une matrice creuse en matrice dense, vous pouvez simplement utiliser la méthode `toarray()` de la matrice creuse :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_sparse : matrice creuse\n",
    "X_dense = X_sparse.toarray()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est donc possible de passer de l'un à l'autre selon vos besoins."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ok, et une telle matrice hybride pourra idem être passée aux méthodes fit et transform de sklearn ?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oui, les matrices creuses hybrides peuvent être utilisées avec les méthodes de Scikit-learn. Scikit-learn prend en charge les formats de matrices creuses standard tels que `csr_matrix`, `csc_matrix` et `coo_matrix`, et cela inclut également les matrices hybrides.\n",
    "\n",
    "Par exemple, si vous utilisez une matrice hybride qui a été créée à l'aide de `hstack`, vous pouvez simplement la passer à une méthode de Scikit-learn telle que suit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Création de la matrice hybride\n",
    "X_hybrid = hstack([X_sparse, X_dense])\n",
    "\n",
    "# Instanciation d'un modèle de régression logistique\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Entraînement du modèle en utilisant la matrice hybride\n",
    "logreg.fit(X_hybrid, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
